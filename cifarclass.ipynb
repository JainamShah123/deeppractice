{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor, Compose\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "myTransforms=Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.GaussianBlur(kernel_size=1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5,0.5,0.5],std=[0.5,0.5,0.5]),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "cifartrain=datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=myTransforms\n",
    ")\n",
    "\n",
    "cifartest=datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=myTransforms\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader=DataLoader(dataset=cifartrain,batch_size=64,shuffle=True,num_workers=6,prefetch_factor=6,pin_memory=True,persistent_workers=True)\n",
    "test_dataloader=DataLoader(dataset=cifartest,batch_size=64,shuffle=True,num_workers=6,prefetch_factor=6,pin_memory=True,persistent_workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(3*32*32, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=1024, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = nn.Softmax(dim=1)(model(X.cuda()))\n",
    "        loss = loss_fn(pred, y.cuda())\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X.cuda())\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = nn.Softmax(dim=1)(model(X.cuda()))\n",
    "            test_loss += loss_fn(pred, y.cuda()).item()\n",
    "            correct += (pred.argmax(1) == y.cuda()).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.303643  [    0/50000]\n",
      "loss: 2.303249  [ 6400/50000]\n",
      "loss: 2.301578  [12800/50000]\n",
      "loss: 2.299190  [19200/50000]\n",
      "loss: 2.298746  [25600/50000]\n",
      "loss: 2.299728  [32000/50000]\n",
      "loss: 2.293784  [38400/50000]\n",
      "loss: 2.292598  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 22.7%, Avg loss: 2.294300 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.293275  [    0/50000]\n",
      "loss: 2.289141  [ 6400/50000]\n",
      "loss: 2.291543  [12800/50000]\n",
      "loss: 2.290916  [19200/50000]\n",
      "loss: 2.283099  [25600/50000]\n",
      "loss: 2.282347  [32000/50000]\n",
      "loss: 2.262152  [38400/50000]\n",
      "loss: 2.274446  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 21.1%, Avg loss: 2.266726 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2.265566  [    0/50000]\n",
      "loss: 2.242507  [ 6400/50000]\n",
      "loss: 2.261005  [12800/50000]\n",
      "loss: 2.260902  [19200/50000]\n",
      "loss: 2.251687  [25600/50000]\n",
      "loss: 2.248219  [32000/50000]\n",
      "loss: 2.232132  [38400/50000]\n",
      "loss: 2.250453  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 23.2%, Avg loss: 2.222099 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 2.173279  [    0/50000]\n",
      "loss: 2.164875  [ 6400/50000]\n",
      "loss: 2.185645  [12800/50000]\n",
      "loss: 2.198817  [19200/50000]\n",
      "loss: 2.178142  [25600/50000]\n",
      "loss: 2.234716  [32000/50000]\n",
      "loss: 2.253036  [38400/50000]\n",
      "loss: 2.262713  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 25.0%, Avg loss: 2.199405 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 2.159393  [    0/50000]\n",
      "loss: 2.258104  [ 6400/50000]\n",
      "loss: 2.173402  [12800/50000]\n",
      "loss: 2.149446  [19200/50000]\n",
      "loss: 2.161667  [25600/50000]\n",
      "loss: 2.180226  [32000/50000]\n",
      "loss: 2.174006  [38400/50000]\n",
      "loss: 2.166176  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 27.7%, Avg loss: 2.182716 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 2.202344  [    0/50000]\n",
      "loss: 2.220709  [ 6400/50000]\n",
      "loss: 2.206942  [12800/50000]\n",
      "loss: 2.145787  [19200/50000]\n",
      "loss: 2.108837  [25600/50000]\n",
      "loss: 2.146142  [32000/50000]\n",
      "loss: 2.215449  [38400/50000]\n",
      "loss: 2.159111  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 30.7%, Avg loss: 2.162934 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 2.086729  [    0/50000]\n",
      "loss: 2.183114  [ 6400/50000]\n",
      "loss: 2.202195  [12800/50000]\n",
      "loss: 2.148860  [19200/50000]\n",
      "loss: 2.094799  [25600/50000]\n",
      "loss: 2.162284  [32000/50000]\n",
      "loss: 2.141875  [38400/50000]\n",
      "loss: 2.156268  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 32.5%, Avg loss: 2.145682 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 2.154308  [    0/50000]\n",
      "loss: 2.066386  [ 6400/50000]\n",
      "loss: 2.166045  [12800/50000]\n",
      "loss: 2.115545  [19200/50000]\n",
      "loss: 2.106312  [25600/50000]\n",
      "loss: 2.123964  [32000/50000]\n",
      "loss: 2.107539  [38400/50000]\n",
      "loss: 2.134062  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 34.4%, Avg loss: 2.128453 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 2.101727  [    0/50000]\n",
      "loss: 2.181018  [ 6400/50000]\n",
      "loss: 2.095762  [12800/50000]\n",
      "loss: 2.181132  [19200/50000]\n",
      "loss: 2.122771  [25600/50000]\n",
      "loss: 2.205148  [32000/50000]\n",
      "loss: 2.111521  [38400/50000]\n",
      "loss: 2.150251  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 35.5%, Avg loss: 2.114937 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 2.107836  [    0/50000]\n",
      "loss: 2.126085  [ 6400/50000]\n",
      "loss: 2.146641  [12800/50000]\n",
      "loss: 2.115614  [19200/50000]\n",
      "loss: 2.107376  [25600/50000]\n",
      "loss: 2.055146  [32000/50000]\n",
      "loss: 2.096686  [38400/50000]\n",
      "loss: 2.102937  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 35.9%, Avg loss: 2.105628 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "learning_rate = 1e-2\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.142179  [    0/50000]\n",
      "loss: 2.081818  [ 6400/50000]\n",
      "loss: 2.082745  [12800/50000]\n",
      "loss: 2.033105  [19200/50000]\n",
      "loss: 2.143479  [25600/50000]\n",
      "loss: 2.089624  [32000/50000]\n",
      "loss: 2.131165  [38400/50000]\n",
      "loss: 2.155652  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 36.6%, Avg loss: 2.097827 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.049086  [    0/50000]\n",
      "loss: 2.031300  [ 6400/50000]\n",
      "loss: 2.100774  [12800/50000]\n",
      "loss: 2.050779  [19200/50000]\n",
      "loss: 2.161657  [25600/50000]\n",
      "loss: 2.139183  [32000/50000]\n",
      "loss: 2.105450  [38400/50000]\n",
      "loss: 2.116628  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 37.1%, Avg loss: 2.090926 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2.167558  [    0/50000]\n",
      "loss: 2.106825  [ 6400/50000]\n",
      "loss: 2.126768  [12800/50000]\n",
      "loss: 2.161480  [19200/50000]\n",
      "loss: 2.122772  [25600/50000]\n",
      "loss: 2.054239  [32000/50000]\n",
      "loss: 2.150550  [38400/50000]\n",
      "loss: 2.169883  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 38.1%, Avg loss: 2.082340 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 2.095978  [    0/50000]\n",
      "loss: 2.106994  [ 6400/50000]\n",
      "loss: 2.048624  [12800/50000]\n",
      "loss: 2.091086  [19200/50000]\n",
      "loss: 1.969332  [25600/50000]\n",
      "loss: 2.037728  [32000/50000]\n",
      "loss: 2.062825  [38400/50000]\n",
      "loss: 2.063415  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 38.6%, Avg loss: 2.076925 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 2.093039  [    0/50000]\n",
      "loss: 2.048961  [ 6400/50000]\n",
      "loss: 2.193928  [12800/50000]\n",
      "loss: 2.125034  [19200/50000]\n",
      "loss: 2.051778  [25600/50000]\n",
      "loss: 2.072869  [32000/50000]\n",
      "loss: 2.091431  [38400/50000]\n",
      "loss: 2.132565  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 39.0%, Avg loss: 2.070998 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 2.073166  [    0/50000]\n",
      "loss: 2.091084  [ 6400/50000]\n",
      "loss: 2.040723  [12800/50000]\n",
      "loss: 2.061404  [19200/50000]\n",
      "loss: 2.073880  [25600/50000]\n",
      "loss: 2.061374  [32000/50000]\n",
      "loss: 2.046434  [38400/50000]\n",
      "loss: 2.042603  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 39.6%, Avg loss: 2.066268 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 2.019988  [    0/50000]\n",
      "loss: 2.033534  [ 6400/50000]\n",
      "loss: 2.009270  [12800/50000]\n",
      "loss: 1.974228  [19200/50000]\n",
      "loss: 2.050836  [25600/50000]\n",
      "loss: 2.164098  [32000/50000]\n",
      "loss: 2.005460  [38400/50000]\n",
      "loss: 2.142692  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 39.9%, Avg loss: 2.062459 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 2.106736  [    0/50000]\n",
      "loss: 2.075653  [ 6400/50000]\n",
      "loss: 2.148110  [12800/50000]\n",
      "loss: 2.028118  [19200/50000]\n",
      "loss: 2.167032  [25600/50000]\n",
      "loss: 2.069695  [32000/50000]\n",
      "loss: 1.996117  [38400/50000]\n",
      "loss: 2.056111  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 40.4%, Avg loss: 2.058653 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 2.139995  [    0/50000]\n",
      "loss: 2.106566  [ 6400/50000]\n",
      "loss: 2.025894  [12800/50000]\n",
      "loss: 2.005236  [19200/50000]\n",
      "loss: 2.149013  [25600/50000]\n",
      "loss: 2.075329  [32000/50000]\n",
      "loss: 1.986413  [38400/50000]\n",
      "loss: 2.013806  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 40.6%, Avg loss: 2.054674 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 2.053154  [    0/50000]\n",
      "loss: 1.950107  [ 6400/50000]\n",
      "loss: 2.095892  [12800/50000]\n",
      "loss: 2.062315  [19200/50000]\n",
      "loss: 2.112551  [25600/50000]\n",
      "loss: 2.055648  [32000/50000]\n",
      "loss: 2.100902  [38400/50000]\n",
      "loss: 2.021941  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 41.1%, Avg loss: 2.051530 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.014812  [    0/50000]\n",
      "loss: 1.934906  [ 6400/50000]\n",
      "loss: 2.057323  [12800/50000]\n",
      "loss: 2.001268  [19200/50000]\n",
      "loss: 2.086144  [25600/50000]\n",
      "loss: 2.135471  [32000/50000]\n",
      "loss: 2.027562  [38400/50000]\n",
      "loss: 2.032734  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 41.3%, Avg loss: 2.048391 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.001186  [    0/50000]\n",
      "loss: 2.158391  [ 6400/50000]\n",
      "loss: 1.976650  [12800/50000]\n",
      "loss: 2.083311  [19200/50000]\n",
      "loss: 2.073504  [25600/50000]\n",
      "loss: 2.031892  [32000/50000]\n",
      "loss: 2.066042  [38400/50000]\n",
      "loss: 2.106697  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 41.7%, Avg loss: 2.044181 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2.067180  [    0/50000]\n",
      "loss: 2.053866  [ 6400/50000]\n",
      "loss: 2.092355  [12800/50000]\n",
      "loss: 2.002193  [19200/50000]\n",
      "loss: 2.073191  [25600/50000]\n",
      "loss: 1.994059  [32000/50000]\n",
      "loss: 2.121749  [38400/50000]\n",
      "loss: 2.014260  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 41.9%, Avg loss: 2.040603 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.976097  [    0/50000]\n",
      "loss: 2.052410  [ 6400/50000]\n",
      "loss: 2.099487  [12800/50000]\n",
      "loss: 2.038738  [19200/50000]\n",
      "loss: 2.098544  [25600/50000]\n",
      "loss: 1.995802  [32000/50000]\n",
      "loss: 2.052573  [38400/50000]\n",
      "loss: 2.057677  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 42.7%, Avg loss: 2.036648 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 2.015511  [    0/50000]\n",
      "loss: 1.953207  [ 6400/50000]\n",
      "loss: 2.062712  [12800/50000]\n",
      "loss: 2.075141  [19200/50000]\n",
      "loss: 2.044932  [25600/50000]\n",
      "loss: 2.105821  [32000/50000]\n",
      "loss: 1.981481  [38400/50000]\n",
      "loss: 2.057654  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 42.9%, Avg loss: 2.032533 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 2.104753  [    0/50000]\n",
      "loss: 1.973082  [ 6400/50000]\n",
      "loss: 2.037584  [12800/50000]\n",
      "loss: 2.031841  [19200/50000]\n",
      "loss: 2.028374  [25600/50000]\n",
      "loss: 2.045328  [32000/50000]\n",
      "loss: 1.971944  [38400/50000]\n",
      "loss: 2.048404  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 43.4%, Avg loss: 2.029191 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 2.021689  [    0/50000]\n",
      "loss: 2.000196  [ 6400/50000]\n",
      "loss: 2.006965  [12800/50000]\n",
      "loss: 2.057864  [19200/50000]\n",
      "loss: 2.023270  [25600/50000]\n",
      "loss: 1.990817  [32000/50000]\n",
      "loss: 2.076279  [38400/50000]\n",
      "loss: 2.063389  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 2.025660 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 2.030375  [    0/50000]\n",
      "loss: 2.000045  [ 6400/50000]\n",
      "loss: 2.033205  [12800/50000]\n",
      "loss: 2.025817  [19200/50000]\n",
      "loss: 2.087362  [25600/50000]\n",
      "loss: 2.011972  [32000/50000]\n",
      "loss: 2.091033  [38400/50000]\n",
      "loss: 1.990957  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 44.2%, Avg loss: 2.020995 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1.940352  [    0/50000]\n",
      "loss: 1.996726  [ 6400/50000]\n",
      "loss: 2.081971  [12800/50000]\n",
      "loss: 2.040430  [19200/50000]\n",
      "loss: 2.031308  [25600/50000]\n",
      "loss: 2.062008  [32000/50000]\n",
      "loss: 2.062452  [38400/50000]\n",
      "loss: 2.031099  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 44.5%, Avg loss: 2.017684 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.958660  [    0/50000]\n",
      "loss: 1.978321  [ 6400/50000]\n",
      "loss: 1.985524  [12800/50000]\n",
      "loss: 2.025219  [19200/50000]\n",
      "loss: 2.032352  [25600/50000]\n",
      "loss: 2.011184  [32000/50000]\n",
      "loss: 1.950250  [38400/50000]\n",
      "loss: 2.049743  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 44.8%, Avg loss: 2.015563 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 1.992224  [    0/50000]\n",
      "loss: 2.078492  [ 6400/50000]\n",
      "loss: 2.023943  [12800/50000]\n",
      "loss: 1.999587  [19200/50000]\n",
      "loss: 2.008497  [25600/50000]\n",
      "loss: 1.966398  [32000/50000]\n",
      "loss: 2.069232  [38400/50000]\n",
      "loss: 1.963491  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 45.6%, Avg loss: 2.010194 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 1.983616  [    0/50000]\n",
      "loss: 1.974157  [ 6400/50000]\n",
      "loss: 2.055196  [12800/50000]\n",
      "loss: 1.963621  [19200/50000]\n",
      "loss: 2.047418  [25600/50000]\n",
      "loss: 1.990863  [32000/50000]\n",
      "loss: 2.004284  [38400/50000]\n",
      "loss: 2.003546  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 45.9%, Avg loss: 2.008736 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 2.021185  [    0/50000]\n",
      "loss: 2.061918  [ 6400/50000]\n",
      "loss: 2.068657  [12800/50000]\n",
      "loss: 1.994029  [19200/50000]\n",
      "loss: 2.067481  [25600/50000]\n",
      "loss: 1.898143  [32000/50000]\n",
      "loss: 1.991142  [38400/50000]\n",
      "loss: 2.059891  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 2.004195 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 1.980433  [    0/50000]\n",
      "loss: 2.032265  [ 6400/50000]\n",
      "loss: 2.022036  [12800/50000]\n",
      "loss: 2.005241  [19200/50000]\n",
      "loss: 1.931276  [25600/50000]\n",
      "loss: 1.931855  [32000/50000]\n",
      "loss: 1.889082  [38400/50000]\n",
      "loss: 1.970839  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 46.3%, Avg loss: 2.002360 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 1.998895  [    0/50000]\n",
      "loss: 1.970638  [ 6400/50000]\n",
      "loss: 2.075039  [12800/50000]\n",
      "loss: 2.054228  [19200/50000]\n",
      "loss: 1.939248  [25600/50000]\n",
      "loss: 1.943876  [32000/50000]\n",
      "loss: 1.997666  [38400/50000]\n",
      "loss: 1.996387  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 46.5%, Avg loss: 1.998741 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 1.991935  [    0/50000]\n",
      "loss: 2.087314  [ 6400/50000]\n",
      "loss: 2.033809  [12800/50000]\n",
      "loss: 1.985780  [19200/50000]\n",
      "loss: 2.019363  [25600/50000]\n",
      "loss: 2.004297  [32000/50000]\n",
      "loss: 1.992706  [38400/50000]\n",
      "loss: 1.994410  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.996615 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 2.043539  [    0/50000]\n",
      "loss: 2.046748  [ 6400/50000]\n",
      "loss: 1.964668  [12800/50000]\n",
      "loss: 2.005472  [19200/50000]\n",
      "loss: 2.052790  [25600/50000]\n",
      "loss: 1.929297  [32000/50000]\n",
      "loss: 1.928516  [38400/50000]\n",
      "loss: 1.978444  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.995381 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 1.973254  [    0/50000]\n",
      "loss: 2.012712  [ 6400/50000]\n",
      "loss: 1.993500  [12800/50000]\n",
      "loss: 1.972580  [19200/50000]\n",
      "loss: 2.045965  [25600/50000]\n",
      "loss: 2.044630  [32000/50000]\n",
      "loss: 1.950347  [38400/50000]\n",
      "loss: 1.993705  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 47.3%, Avg loss: 1.992470 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 1.932034  [    0/50000]\n",
      "loss: 2.019756  [ 6400/50000]\n",
      "loss: 1.969822  [12800/50000]\n",
      "loss: 2.013188  [19200/50000]\n",
      "loss: 1.905073  [25600/50000]\n",
      "loss: 1.947516  [32000/50000]\n",
      "loss: 2.022479  [38400/50000]\n",
      "loss: 1.989683  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 47.4%, Avg loss: 1.990107 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 1.947388  [    0/50000]\n",
      "loss: 1.960516  [ 6400/50000]\n",
      "loss: 2.001063  [12800/50000]\n",
      "loss: 1.954324  [19200/50000]\n",
      "loss: 1.905802  [25600/50000]\n",
      "loss: 2.005669  [32000/50000]\n",
      "loss: 2.021253  [38400/50000]\n",
      "loss: 1.952559  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 47.4%, Avg loss: 1.988713 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.005113  [    0/50000]\n",
      "loss: 2.004045  [ 6400/50000]\n",
      "loss: 1.990114  [12800/50000]\n",
      "loss: 2.037858  [19200/50000]\n",
      "loss: 2.017127  [25600/50000]\n",
      "loss: 1.973101  [32000/50000]\n",
      "loss: 1.921767  [38400/50000]\n",
      "loss: 1.953205  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 47.6%, Avg loss: 1.987495 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.949969  [    0/50000]\n",
      "loss: 1.931570  [ 6400/50000]\n",
      "loss: 2.054480  [12800/50000]\n",
      "loss: 2.040109  [19200/50000]\n",
      "loss: 1.910775  [25600/50000]\n",
      "loss: 1.845672  [32000/50000]\n",
      "loss: 1.949991  [38400/50000]\n",
      "loss: 1.962227  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 47.8%, Avg loss: 1.984038 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.970906  [    0/50000]\n",
      "loss: 1.881516  [ 6400/50000]\n",
      "loss: 1.997230  [12800/50000]\n",
      "loss: 2.003773  [19200/50000]\n",
      "loss: 2.063114  [25600/50000]\n",
      "loss: 1.900756  [32000/50000]\n",
      "loss: 1.978169  [38400/50000]\n",
      "loss: 2.011283  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 47.9%, Avg loss: 1.982088 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 2.101023  [    0/50000]\n",
      "loss: 1.946679  [ 6400/50000]\n",
      "loss: 1.963036  [12800/50000]\n",
      "loss: 1.997426  [19200/50000]\n",
      "loss: 1.972937  [25600/50000]\n",
      "loss: 1.974439  [32000/50000]\n",
      "loss: 2.038722  [38400/50000]\n",
      "loss: 1.985738  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 48.2%, Avg loss: 1.980651 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.954506  [    0/50000]\n",
      "loss: 1.944825  [ 6400/50000]\n",
      "loss: 1.915416  [12800/50000]\n",
      "loss: 1.973331  [19200/50000]\n",
      "loss: 1.890712  [25600/50000]\n",
      "loss: 1.843558  [32000/50000]\n",
      "loss: 1.967919  [38400/50000]\n",
      "loss: 1.929744  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 48.0%, Avg loss: 1.981271 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.901249  [    0/50000]\n",
      "loss: 1.965556  [ 6400/50000]\n",
      "loss: 2.063170  [12800/50000]\n",
      "loss: 2.023227  [19200/50000]\n",
      "loss: 1.993816  [25600/50000]\n",
      "loss: 1.871034  [32000/50000]\n",
      "loss: 1.975393  [38400/50000]\n",
      "loss: 1.958958  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 48.5%, Avg loss: 1.978395 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.926232  [    0/50000]\n",
      "loss: 1.935437  [ 6400/50000]\n",
      "loss: 2.070377  [12800/50000]\n",
      "loss: 1.967076  [19200/50000]\n",
      "loss: 2.036873  [25600/50000]\n",
      "loss: 1.980494  [32000/50000]\n",
      "loss: 2.026790  [38400/50000]\n",
      "loss: 2.036779  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 48.5%, Avg loss: 1.976447 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.987655  [    0/50000]\n",
      "loss: 1.917190  [ 6400/50000]\n",
      "loss: 1.970126  [12800/50000]\n",
      "loss: 1.950830  [19200/50000]\n",
      "loss: 2.025343  [25600/50000]\n",
      "loss: 1.941105  [32000/50000]\n",
      "loss: 1.984334  [38400/50000]\n",
      "loss: 1.956349  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 48.9%, Avg loss: 1.974461 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 2.001916  [    0/50000]\n",
      "loss: 1.886850  [ 6400/50000]\n",
      "loss: 1.996162  [12800/50000]\n",
      "loss: 1.885191  [19200/50000]\n",
      "loss: 2.003505  [25600/50000]\n",
      "loss: 1.955407  [32000/50000]\n",
      "loss: 1.976627  [38400/50000]\n",
      "loss: 1.919768  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 49.0%, Avg loss: 1.972470 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.985051  [    0/50000]\n",
      "loss: 1.950822  [ 6400/50000]\n",
      "loss: 2.000442  [12800/50000]\n",
      "loss: 1.955851  [19200/50000]\n",
      "loss: 1.973840  [25600/50000]\n",
      "loss: 2.019126  [32000/50000]\n",
      "loss: 1.927460  [38400/50000]\n",
      "loss: 1.968874  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 49.0%, Avg loss: 1.969475 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 1.937127  [    0/50000]\n",
      "loss: 1.919265  [ 6400/50000]\n",
      "loss: 1.892401  [12800/50000]\n",
      "loss: 1.911781  [19200/50000]\n",
      "loss: 2.026773  [25600/50000]\n",
      "loss: 1.973085  [32000/50000]\n",
      "loss: 1.925500  [38400/50000]\n",
      "loss: 2.029307  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 49.5%, Avg loss: 1.968143 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 1.942912  [    0/50000]\n",
      "loss: 1.925692  [ 6400/50000]\n",
      "loss: 1.864722  [12800/50000]\n",
      "loss: 1.937490  [19200/50000]\n",
      "loss: 1.922401  [25600/50000]\n",
      "loss: 1.854793  [32000/50000]\n",
      "loss: 1.909069  [38400/50000]\n",
      "loss: 1.902726  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 1.967181 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 1.937626  [    0/50000]\n",
      "loss: 1.982642  [ 6400/50000]\n",
      "loss: 1.928779  [12800/50000]\n",
      "loss: 1.956963  [19200/50000]\n",
      "loss: 2.019713  [25600/50000]\n",
      "loss: 1.946898  [32000/50000]\n",
      "loss: 1.976709  [38400/50000]\n",
      "loss: 1.937136  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 49.4%, Avg loss: 1.968197 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 1.829775  [    0/50000]\n",
      "loss: 1.941350  [ 6400/50000]\n",
      "loss: 2.033131  [12800/50000]\n",
      "loss: 1.910592  [19200/50000]\n",
      "loss: 1.885892  [25600/50000]\n",
      "loss: 1.853764  [32000/50000]\n",
      "loss: 1.921482  [38400/50000]\n",
      "loss: 1.878780  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 49.6%, Avg loss: 1.966761 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 1.892684  [    0/50000]\n",
      "loss: 1.940833  [ 6400/50000]\n",
      "loss: 1.874852  [12800/50000]\n",
      "loss: 1.869573  [19200/50000]\n",
      "loss: 1.944344  [25600/50000]\n",
      "loss: 1.926648  [32000/50000]\n",
      "loss: 1.968937  [38400/50000]\n",
      "loss: 1.980109  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 1.965221 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 1.989686  [    0/50000]\n",
      "loss: 1.922337  [ 6400/50000]\n",
      "loss: 1.927250  [12800/50000]\n",
      "loss: 1.881412  [19200/50000]\n",
      "loss: 1.989195  [25600/50000]\n",
      "loss: 1.909631  [32000/50000]\n",
      "loss: 1.866706  [38400/50000]\n",
      "loss: 1.881728  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 1.962389 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 1.866570  [    0/50000]\n",
      "loss: 1.995103  [ 6400/50000]\n",
      "loss: 1.883885  [12800/50000]\n",
      "loss: 1.933059  [19200/50000]\n",
      "loss: 1.976192  [25600/50000]\n",
      "loss: 1.951830  [32000/50000]\n",
      "loss: 1.924814  [38400/50000]\n",
      "loss: 1.885254  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 50.7%, Avg loss: 1.958700 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 1.933016  [    0/50000]\n",
      "loss: 1.957824  [ 6400/50000]\n",
      "loss: 1.854675  [12800/50000]\n",
      "loss: 1.919824  [19200/50000]\n",
      "loss: 1.906804  [25600/50000]\n",
      "loss: 1.958741  [32000/50000]\n",
      "loss: 2.003792  [38400/50000]\n",
      "loss: 1.977514  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 50.4%, Avg loss: 1.958048 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 1.883842  [    0/50000]\n",
      "loss: 1.992737  [ 6400/50000]\n",
      "loss: 1.884461  [12800/50000]\n",
      "loss: 1.918549  [19200/50000]\n",
      "loss: 1.979752  [25600/50000]\n",
      "loss: 2.105199  [32000/50000]\n",
      "loss: 1.845403  [38400/50000]\n",
      "loss: 1.970211  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 50.6%, Avg loss: 1.959229 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 1.940369  [    0/50000]\n",
      "loss: 1.830218  [ 6400/50000]\n",
      "loss: 1.974050  [12800/50000]\n",
      "loss: 1.882430  [19200/50000]\n",
      "loss: 1.974848  [25600/50000]\n",
      "loss: 1.928504  [32000/50000]\n",
      "loss: 1.988181  [38400/50000]\n",
      "loss: 1.924503  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 50.7%, Avg loss: 1.954773 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 1.874249  [    0/50000]\n",
      "loss: 1.756712  [ 6400/50000]\n",
      "loss: 1.866430  [12800/50000]\n",
      "loss: 1.928573  [19200/50000]\n",
      "loss: 1.907868  [25600/50000]\n",
      "loss: 1.876669  [32000/50000]\n",
      "loss: 1.958973  [38400/50000]\n",
      "loss: 1.870797  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 50.7%, Avg loss: 1.956511 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 1.961310  [    0/50000]\n",
      "loss: 1.949793  [ 6400/50000]\n",
      "loss: 2.001467  [12800/50000]\n",
      "loss: 2.006647  [19200/50000]\n",
      "loss: 1.880337  [25600/50000]\n",
      "loss: 1.960522  [32000/50000]\n",
      "loss: 2.010792  [38400/50000]\n",
      "loss: 1.926872  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 50.3%, Avg loss: 1.956600 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 1.988296  [    0/50000]\n",
      "loss: 1.847756  [ 6400/50000]\n",
      "loss: 1.833989  [12800/50000]\n",
      "loss: 1.946112  [19200/50000]\n",
      "loss: 2.010517  [25600/50000]\n",
      "loss: 1.972396  [32000/50000]\n",
      "loss: 1.951445  [38400/50000]\n",
      "loss: 2.053691  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 51.1%, Avg loss: 1.954816 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 1.927157  [    0/50000]\n",
      "loss: 1.939840  [ 6400/50000]\n",
      "loss: 1.860713  [12800/50000]\n",
      "loss: 1.931691  [19200/50000]\n",
      "loss: 2.008921  [25600/50000]\n",
      "loss: 1.940150  [32000/50000]\n",
      "loss: 2.006843  [38400/50000]\n",
      "loss: 1.914456  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 50.9%, Avg loss: 1.950953 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 1.995759  [    0/50000]\n",
      "loss: 1.901807  [ 6400/50000]\n",
      "loss: 2.049917  [12800/50000]\n",
      "loss: 1.845707  [19200/50000]\n",
      "loss: 1.948272  [25600/50000]\n",
      "loss: 1.830897  [32000/50000]\n",
      "loss: 1.830924  [38400/50000]\n",
      "loss: 1.972020  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 51.6%, Avg loss: 1.948675 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 1.954279  [    0/50000]\n",
      "loss: 1.948306  [ 6400/50000]\n",
      "loss: 1.940310  [12800/50000]\n",
      "loss: 1.951163  [19200/50000]\n",
      "loss: 1.947758  [25600/50000]\n",
      "loss: 1.918860  [32000/50000]\n",
      "loss: 1.994406  [38400/50000]\n",
      "loss: 1.978443  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 51.2%, Avg loss: 1.950703 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 1.906298  [    0/50000]\n",
      "loss: 1.905645  [ 6400/50000]\n",
      "loss: 1.959949  [12800/50000]\n",
      "loss: 1.828704  [19200/50000]\n",
      "loss: 1.802356  [25600/50000]\n",
      "loss: 1.888364  [32000/50000]\n",
      "loss: 1.893274  [38400/50000]\n",
      "loss: 1.852465  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 51.5%, Avg loss: 1.948059 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 1.919810  [    0/50000]\n",
      "loss: 1.917333  [ 6400/50000]\n",
      "loss: 1.910361  [12800/50000]\n",
      "loss: 1.906511  [19200/50000]\n",
      "loss: 1.890210  [25600/50000]\n",
      "loss: 1.822735  [32000/50000]\n",
      "loss: 1.965544  [38400/50000]\n",
      "loss: 1.852014  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 51.6%, Avg loss: 1.947744 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 1.984864  [    0/50000]\n",
      "loss: 1.849722  [ 6400/50000]\n",
      "loss: 1.860776  [12800/50000]\n",
      "loss: 2.046860  [19200/50000]\n",
      "loss: 1.855906  [25600/50000]\n",
      "loss: 1.884025  [32000/50000]\n",
      "loss: 1.958585  [38400/50000]\n",
      "loss: 1.975283  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 1.944465 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 2.048403  [    0/50000]\n",
      "loss: 1.826165  [ 6400/50000]\n",
      "loss: 1.897402  [12800/50000]\n",
      "loss: 1.932514  [19200/50000]\n",
      "loss: 1.938609  [25600/50000]\n",
      "loss: 1.833404  [32000/50000]\n",
      "loss: 1.886793  [38400/50000]\n",
      "loss: 1.796518  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 52.0%, Avg loss: 1.945553 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.920785  [    0/50000]\n",
      "loss: 1.934054  [ 6400/50000]\n",
      "loss: 1.952598  [12800/50000]\n",
      "loss: 1.901371  [19200/50000]\n",
      "loss: 1.910089  [25600/50000]\n",
      "loss: 1.883180  [32000/50000]\n",
      "loss: 1.806921  [38400/50000]\n",
      "loss: 1.841329  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 1.945338 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.867405  [    0/50000]\n",
      "loss: 1.877015  [ 6400/50000]\n",
      "loss: 1.950830  [12800/50000]\n",
      "loss: 1.840381  [19200/50000]\n",
      "loss: 1.930893  [25600/50000]\n",
      "loss: 1.892443  [32000/50000]\n",
      "loss: 1.808964  [38400/50000]\n",
      "loss: 1.946589  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 52.0%, Avg loss: 1.943739 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.861831  [    0/50000]\n",
      "loss: 1.983016  [ 6400/50000]\n",
      "loss: 1.979768  [12800/50000]\n",
      "loss: 1.833803  [19200/50000]\n",
      "loss: 1.958081  [25600/50000]\n",
      "loss: 1.854154  [32000/50000]\n",
      "loss: 1.936655  [38400/50000]\n",
      "loss: 2.013726  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 52.3%, Avg loss: 1.942776 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.828172  [    0/50000]\n",
      "loss: 1.905019  [ 6400/50000]\n",
      "loss: 2.015340  [12800/50000]\n",
      "loss: 1.853591  [19200/50000]\n",
      "loss: 1.985939  [25600/50000]\n",
      "loss: 1.916081  [32000/50000]\n",
      "loss: 1.963007  [38400/50000]\n",
      "loss: 1.927621  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 52.4%, Avg loss: 1.940049 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.857129  [    0/50000]\n",
      "loss: 1.822324  [ 6400/50000]\n",
      "loss: 1.889061  [12800/50000]\n",
      "loss: 1.823462  [19200/50000]\n",
      "loss: 1.932737  [25600/50000]\n",
      "loss: 1.887332  [32000/50000]\n",
      "loss: 1.949288  [38400/50000]\n",
      "loss: 1.843218  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 52.3%, Avg loss: 1.940713 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.799040  [    0/50000]\n",
      "loss: 1.944423  [ 6400/50000]\n",
      "loss: 1.839684  [12800/50000]\n",
      "loss: 1.931781  [19200/50000]\n",
      "loss: 1.890094  [25600/50000]\n",
      "loss: 1.813744  [32000/50000]\n",
      "loss: 1.919639  [38400/50000]\n",
      "loss: 1.911668  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 52.1%, Avg loss: 1.939808 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.941473  [    0/50000]\n",
      "loss: 1.879899  [ 6400/50000]\n",
      "loss: 1.907778  [12800/50000]\n",
      "loss: 1.939031  [19200/50000]\n",
      "loss: 1.860931  [25600/50000]\n",
      "loss: 1.911334  [32000/50000]\n",
      "loss: 1.885648  [38400/50000]\n",
      "loss: 1.858978  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 52.6%, Avg loss: 1.937230 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.995176  [    0/50000]\n",
      "loss: 1.902158  [ 6400/50000]\n",
      "loss: 1.903422  [12800/50000]\n",
      "loss: 1.973930  [19200/50000]\n",
      "loss: 1.866446  [25600/50000]\n",
      "loss: 1.863676  [32000/50000]\n",
      "loss: 1.847746  [38400/50000]\n",
      "loss: 1.829064  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 52.4%, Avg loss: 1.937803 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1.843877  [    0/50000]\n",
      "loss: 1.870639  [ 6400/50000]\n",
      "loss: 1.830074  [12800/50000]\n",
      "loss: 1.953279  [19200/50000]\n",
      "loss: 1.809808  [25600/50000]\n",
      "loss: 1.915523  [32000/50000]\n",
      "loss: 1.912585  [38400/50000]\n",
      "loss: 1.865000  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 52.5%, Avg loss: 1.936628 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.890709  [    0/50000]\n",
      "loss: 1.895714  [ 6400/50000]\n",
      "loss: 1.881591  [12800/50000]\n",
      "loss: 1.934322  [19200/50000]\n",
      "loss: 1.925972  [25600/50000]\n",
      "loss: 1.841928  [32000/50000]\n",
      "loss: 1.918370  [38400/50000]\n",
      "loss: 1.877515  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 1.936741 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 1.944804  [    0/50000]\n",
      "loss: 1.754443  [ 6400/50000]\n",
      "loss: 1.791376  [12800/50000]\n",
      "loss: 1.913778  [19200/50000]\n",
      "loss: 1.825635  [25600/50000]\n",
      "loss: 1.858168  [32000/50000]\n",
      "loss: 1.899570  [38400/50000]\n",
      "loss: 1.800346  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 52.7%, Avg loss: 1.935557 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 1.892624  [    0/50000]\n",
      "loss: 1.837336  [ 6400/50000]\n",
      "loss: 1.922716  [12800/50000]\n",
      "loss: 1.944648  [19200/50000]\n",
      "loss: 1.956884  [25600/50000]\n",
      "loss: 1.943882  [32000/50000]\n",
      "loss: 1.868527  [38400/50000]\n",
      "loss: 1.891162  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 1.935449 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 1.867713  [    0/50000]\n",
      "loss: 1.854512  [ 6400/50000]\n",
      "loss: 1.845875  [12800/50000]\n",
      "loss: 1.873273  [19200/50000]\n",
      "loss: 1.871483  [25600/50000]\n",
      "loss: 1.857387  [32000/50000]\n",
      "loss: 1.861382  [38400/50000]\n",
      "loss: 1.895655  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 52.7%, Avg loss: 1.936603 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 1.748733  [    0/50000]\n",
      "loss: 1.791109  [ 6400/50000]\n",
      "loss: 1.843790  [12800/50000]\n",
      "loss: 1.771264  [19200/50000]\n",
      "loss: 1.785542  [25600/50000]\n",
      "loss: 1.819779  [32000/50000]\n",
      "loss: 1.912701  [38400/50000]\n",
      "loss: 1.975853  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 1.931605 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 1.958321  [    0/50000]\n",
      "loss: 1.851541  [ 6400/50000]\n",
      "loss: 1.797593  [12800/50000]\n",
      "loss: 1.912127  [19200/50000]\n",
      "loss: 1.853954  [25600/50000]\n",
      "loss: 1.903475  [32000/50000]\n",
      "loss: 1.907968  [38400/50000]\n",
      "loss: 1.796491  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.932814 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 1.905437  [    0/50000]\n",
      "loss: 1.917783  [ 6400/50000]\n",
      "loss: 1.879366  [12800/50000]\n",
      "loss: 1.825888  [19200/50000]\n",
      "loss: 1.854133  [25600/50000]\n",
      "loss: 1.875803  [32000/50000]\n",
      "loss: 1.833843  [38400/50000]\n",
      "loss: 1.788042  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 52.3%, Avg loss: 1.936616 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 1.716293  [    0/50000]\n",
      "loss: 1.769875  [ 6400/50000]\n",
      "loss: 1.818009  [12800/50000]\n",
      "loss: 1.816660  [19200/50000]\n",
      "loss: 1.885899  [25600/50000]\n",
      "loss: 1.867360  [32000/50000]\n",
      "loss: 1.871847  [38400/50000]\n",
      "loss: 1.848446  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 53.5%, Avg loss: 1.929161 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 1.922060  [    0/50000]\n",
      "loss: 1.864438  [ 6400/50000]\n",
      "loss: 1.894704  [12800/50000]\n",
      "loss: 1.937398  [19200/50000]\n",
      "loss: 1.766159  [25600/50000]\n",
      "loss: 1.867061  [32000/50000]\n",
      "loss: 1.796138  [38400/50000]\n",
      "loss: 1.838873  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 53.3%, Avg loss: 1.930935 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 1.856051  [    0/50000]\n",
      "loss: 1.811671  [ 6400/50000]\n",
      "loss: 1.878446  [12800/50000]\n",
      "loss: 1.837651  [19200/50000]\n",
      "loss: 1.843896  [25600/50000]\n",
      "loss: 1.941373  [32000/50000]\n",
      "loss: 1.838156  [38400/50000]\n",
      "loss: 1.809900  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 53.6%, Avg loss: 1.929134 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 1.867931  [    0/50000]\n",
      "loss: 1.814348  [ 6400/50000]\n",
      "loss: 1.843479  [12800/50000]\n",
      "loss: 1.851843  [19200/50000]\n",
      "loss: 1.817938  [25600/50000]\n",
      "loss: 1.896909  [32000/50000]\n",
      "loss: 1.852464  [38400/50000]\n",
      "loss: 1.859556  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 53.6%, Avg loss: 1.928210 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 1.943076  [    0/50000]\n",
      "loss: 1.814121  [ 6400/50000]\n",
      "loss: 1.851976  [12800/50000]\n",
      "loss: 1.789014  [19200/50000]\n",
      "loss: 1.811605  [25600/50000]\n",
      "loss: 1.837862  [32000/50000]\n",
      "loss: 1.870901  [38400/50000]\n",
      "loss: 1.799670  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 53.3%, Avg loss: 1.928895 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 1.717419  [    0/50000]\n",
      "loss: 1.864957  [ 6400/50000]\n",
      "loss: 1.886631  [12800/50000]\n",
      "loss: 1.842912  [19200/50000]\n",
      "loss: 1.793157  [25600/50000]\n",
      "loss: 1.831013  [32000/50000]\n",
      "loss: 1.851044  [38400/50000]\n",
      "loss: 1.821786  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 1.927977 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 1.882425  [    0/50000]\n",
      "loss: 1.920758  [ 6400/50000]\n",
      "loss: 1.928767  [12800/50000]\n",
      "loss: 1.753393  [19200/50000]\n",
      "loss: 1.803453  [25600/50000]\n",
      "loss: 1.912594  [32000/50000]\n",
      "loss: 1.895079  [38400/50000]\n",
      "loss: 1.814623  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 53.9%, Avg loss: 1.924633 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 1.784648  [    0/50000]\n",
      "loss: 1.934056  [ 6400/50000]\n",
      "loss: 1.870184  [12800/50000]\n",
      "loss: 1.916756  [19200/50000]\n",
      "loss: 1.804074  [25600/50000]\n",
      "loss: 1.845967  [32000/50000]\n",
      "loss: 1.810953  [38400/50000]\n",
      "loss: 1.801802  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 53.1%, Avg loss: 1.931308 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 1.852240  [    0/50000]\n",
      "loss: 1.919534  [ 6400/50000]\n",
      "loss: 1.860932  [12800/50000]\n",
      "loss: 1.734265  [19200/50000]\n",
      "loss: 1.838723  [25600/50000]\n",
      "loss: 1.899073  [32000/50000]\n",
      "loss: 1.832935  [38400/50000]\n",
      "loss: 1.899003  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 52.6%, Avg loss: 1.933057 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 1.915471  [    0/50000]\n",
      "loss: 1.853555  [ 6400/50000]\n",
      "loss: 1.896712  [12800/50000]\n",
      "loss: 1.888715  [19200/50000]\n",
      "loss: 1.880602  [25600/50000]\n",
      "loss: 1.900220  [32000/50000]\n",
      "loss: 1.788038  [38400/50000]\n",
      "loss: 1.896298  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 53.9%, Avg loss: 1.923092 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 1.760979  [    0/50000]\n",
      "loss: 1.879042  [ 6400/50000]\n",
      "loss: 1.894158  [12800/50000]\n",
      "loss: 1.844503  [19200/50000]\n",
      "loss: 1.908933  [25600/50000]\n",
      "loss: 1.897809  [32000/50000]\n",
      "loss: 1.793714  [38400/50000]\n",
      "loss: 1.789854  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 1.923399 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 1.872809  [    0/50000]\n",
      "loss: 1.766351  [ 6400/50000]\n",
      "loss: 1.890199  [12800/50000]\n",
      "loss: 1.754513  [19200/50000]\n",
      "loss: 1.844377  [25600/50000]\n",
      "loss: 1.879230  [32000/50000]\n",
      "loss: 1.851420  [38400/50000]\n",
      "loss: 1.831780  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 1.922914 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 1.756899  [    0/50000]\n",
      "loss: 1.774569  [ 6400/50000]\n",
      "loss: 1.892992  [12800/50000]\n",
      "loss: 1.816950  [19200/50000]\n",
      "loss: 1.850649  [25600/50000]\n",
      "loss: 1.791565  [32000/50000]\n",
      "loss: 1.813190  [38400/50000]\n",
      "loss: 1.823670  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 1.924264 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 1.802304  [    0/50000]\n",
      "loss: 1.798857  [ 6400/50000]\n",
      "loss: 1.831112  [12800/50000]\n",
      "loss: 1.843624  [19200/50000]\n",
      "loss: 1.844200  [25600/50000]\n",
      "loss: 1.895885  [32000/50000]\n",
      "loss: 1.724351  [38400/50000]\n",
      "loss: 1.863484  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 54.1%, Avg loss: 1.921955 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 1.821628  [    0/50000]\n",
      "loss: 1.846285  [ 6400/50000]\n",
      "loss: 1.875119  [12800/50000]\n",
      "loss: 1.864647  [19200/50000]\n",
      "loss: 1.773931  [25600/50000]\n",
      "loss: 1.809258  [32000/50000]\n",
      "loss: 1.721676  [38400/50000]\n",
      "loss: 1.774333  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 54.2%, Avg loss: 1.922308 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 1.754230  [    0/50000]\n",
      "loss: 1.751876  [ 6400/50000]\n",
      "loss: 1.793282  [12800/50000]\n",
      "loss: 1.756053  [19200/50000]\n",
      "loss: 1.744320  [25600/50000]\n",
      "loss: 1.869839  [32000/50000]\n",
      "loss: 1.724599  [38400/50000]\n",
      "loss: 1.860723  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 1.921764 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 1.822554  [    0/50000]\n",
      "loss: 1.899024  [ 6400/50000]\n",
      "loss: 1.828832  [12800/50000]\n",
      "loss: 1.876439  [19200/50000]\n",
      "loss: 1.800750  [25600/50000]\n",
      "loss: 1.837546  [32000/50000]\n",
      "loss: 1.905758  [38400/50000]\n",
      "loss: 1.871421  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 1.921918 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 1.852098  [    0/50000]\n",
      "loss: 1.855485  [ 6400/50000]\n",
      "loss: 1.848870  [12800/50000]\n",
      "loss: 1.912104  [19200/50000]\n",
      "loss: 1.803627  [25600/50000]\n",
      "loss: 1.948469  [32000/50000]\n",
      "loss: 1.800106  [38400/50000]\n",
      "loss: 1.751809  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 53.9%, Avg loss: 1.922523 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 1.748106  [    0/50000]\n",
      "loss: 1.802107  [ 6400/50000]\n",
      "loss: 1.804672  [12800/50000]\n",
      "loss: 1.728058  [19200/50000]\n",
      "loss: 1.720043  [25600/50000]\n",
      "loss: 1.827126  [32000/50000]\n",
      "loss: 1.929970  [38400/50000]\n",
      "loss: 1.809932  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 54.2%, Avg loss: 1.921860 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 1.822777  [    0/50000]\n",
      "loss: 1.748990  [ 6400/50000]\n",
      "loss: 1.861570  [12800/50000]\n",
      "loss: 1.828768  [19200/50000]\n",
      "loss: 1.939244  [25600/50000]\n",
      "loss: 1.779852  [32000/50000]\n",
      "loss: 1.813887  [38400/50000]\n",
      "loss: 1.875513  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 54.3%, Avg loss: 1.918648 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 1.878636  [    0/50000]\n",
      "loss: 1.776948  [ 6400/50000]\n",
      "loss: 1.897592  [12800/50000]\n",
      "loss: 1.823875  [19200/50000]\n",
      "loss: 1.853431  [25600/50000]\n",
      "loss: 1.880587  [32000/50000]\n",
      "loss: 1.792402  [38400/50000]\n",
      "loss: 1.862091  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 54.1%, Avg loss: 1.918300 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 1.873735  [    0/50000]\n",
      "loss: 1.842421  [ 6400/50000]\n",
      "loss: 1.776152  [12800/50000]\n",
      "loss: 1.857003  [19200/50000]\n",
      "loss: 1.757592  [25600/50000]\n",
      "loss: 1.849814  [32000/50000]\n",
      "loss: 1.888547  [38400/50000]\n",
      "loss: 1.812326  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 1.918459 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 1.804310  [    0/50000]\n",
      "loss: 1.721805  [ 6400/50000]\n",
      "loss: 1.798208  [12800/50000]\n",
      "loss: 1.866494  [19200/50000]\n",
      "loss: 1.820931  [25600/50000]\n",
      "loss: 1.842773  [32000/50000]\n",
      "loss: 1.805316  [38400/50000]\n",
      "loss: 1.882969  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 54.1%, Avg loss: 1.919612 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 1.797021  [    0/50000]\n",
      "loss: 1.850994  [ 6400/50000]\n",
      "loss: 1.814191  [12800/50000]\n",
      "loss: 1.809471  [19200/50000]\n",
      "loss: 1.832681  [25600/50000]\n",
      "loss: 1.834430  [32000/50000]\n",
      "loss: 1.812420  [38400/50000]\n",
      "loss: 1.768319  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 54.1%, Avg loss: 1.918051 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 40\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
